# -*- coding: utf-8 -*-
"""Generic QnA App.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZTJYYM6UJBbweOP1D1_hayO5ixKE1GAj
"""

from langchain.schema import SystemMessage,AIMessage,HumanMessage
from langchain.chat_models import ChatOpenAI
import streamlit as s

model=ChatOpenAI(openai_api_key="write your own open ai api key here",temperature=0.7)

s.set_page_config(page_title="This is a conversational AI")
s.header("What is your query ?")

if 'flowmessages' not in s.session_state:
  s.session_state['flowmessages']=[SystemMessage(content="Act like a generic AI model to complete responses within 100 words")]


def response_from_model(question):
  s.session_state['flowmessages'].append(HumanMessage(content=question))
  answer=model(s.session_state['flowmessages'])
  s.session_state['flowmessages'].append(AIMessage(content=answer.content))
  return answer.content

input=s.text_input("Write here :",key="input")
response=response_from_model(input)

submit=s.button("Click here to submit")

if submit:
  s.subheader("AI says")
  s.write(response)